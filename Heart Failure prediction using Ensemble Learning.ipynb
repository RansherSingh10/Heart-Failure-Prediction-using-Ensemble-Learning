{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seminar - Heart Failure (Final)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8X8xDwS6vgS"
      },
      "source": [
        "# Heart Disease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEGG4I6n60cM"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4b029YC7C-y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa536pRY7Eq5"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4POXlqg47Ny3"
      },
      "source": [
        "dataset = pd.read_csv('Heart Faliure - Seminar.csv')\n",
        "X = dataset.iloc[:, :12].values\n",
        "y = dataset.iloc[:, 12].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd063siPFb9_"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAlLqCs_Ff30"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS1Q-n_A7iZ_"
      },
      "source": [
        "## Training different models on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V-LgiUa78lX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db613137-d6a7-43f2-b515-62c1c6e84909"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = AdaBoostClassifier(LogisticRegression(),n_estimators = 5, learning_rate = 1)\n",
        "lr.fit(X,y)\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "SVM = SVC(kernel = 'linear')\n",
        "SVM.fit(X, y)\n",
        "\n",
        "#Kernel SVM\n",
        "from sklearn.svm import SVC\n",
        "kSVM = SVC(kernel = 'sigmoid')\n",
        "kSVM.fit(X, y)\n",
        "\n",
        "#Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X, y)\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(criterion = 'entropy')\n",
        "dt.fit(X, y)\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = AdaBoostClassifier(RandomForestClassifier(n_estimators=10, criterion = 'entropy'),n_estimators = 5, learning_rate = 1)\n",
        "rf.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                         ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='entropy',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features='auto',\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         max_samples=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         n_estimators=10,\n",
              "                                                         n_jobs=None,\n",
              "                                                         oob_score=False,\n",
              "                                                         random_state=None,\n",
              "                                                         verbose=0,\n",
              "                                                         warm_start=False),\n",
              "                   learning_rate=1, n_estimators=5, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa6kQufsv2WJ"
      },
      "source": [
        "## Checking accuracy to adjust weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7avEyotv755"
      },
      "source": [
        "lr_score = lr.score(X,y)\n",
        "SVM_score = SVM.score(X,y)\n",
        "kSVM_score = kSVM.score(X,y)\n",
        "nb_score = nb.score(X,y)\n",
        "dt_score = dt.score(X,y)\n",
        "rf_score = rf.score(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o6EPoG2_GM9"
      },
      "source": [
        "sum = lr_score + SVM_score + kSVM_score + nb_score + dt_score + rf_score\n",
        "lr_score /= sum\n",
        "SVM_score /= sum\n",
        "kSVM_score /= sum\n",
        "nb_score /= sum\n",
        "dt_score /= sum\n",
        "rf_score /= sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlNqBxkz3lv"
      },
      "source": [
        "## Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjcXszORz7At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8b1460-256c-47c3-8212-391e181b40a3"
      },
      "source": [
        "from sklearn. ensemble import VotingClassifier\n",
        "evc = VotingClassifier( estimators= [('lr',lr),('SVM',SVM),('kSVM',kSVM),('nb',nb),('dt',dt),('rf',rf)], voting = 'hard', weights=[lr_score, SVM_score, kSVM_score, nb_score,dt_score,rf_score])\n",
        "evc.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr',\n",
              "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                 base_estimator=LogisticRegression(C=1.0,\n",
              "                                                                                   class_weight=None,\n",
              "                                                                                   dual=False,\n",
              "                                                                                   fit_intercept=True,\n",
              "                                                                                   intercept_scaling=1,\n",
              "                                                                                   l1_ratio=None,\n",
              "                                                                                   max_iter=100,\n",
              "                                                                                   multi_class='auto',\n",
              "                                                                                   n_jobs=None,\n",
              "                                                                                   penalty='l2',\n",
              "                                                                                   random_state=None,\n",
              "                                                                                   solver='lbfgs',\n",
              "                                                                                   tol=0.0001,\n",
              "                                                                                   verbose=0,\n",
              "                                                                                   warm_start=False),\n",
              "                                                 learning_rate=1,\n",
              "                                                 n_estimat...\n",
              "                                                                                       min_samples_split=2,\n",
              "                                                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                                                       n_estimators=10,\n",
              "                                                                                       n_jobs=None,\n",
              "                                                                                       oob_score=False,\n",
              "                                                                                       random_state=None,\n",
              "                                                                                       verbose=0,\n",
              "                                                                                       warm_start=False),\n",
              "                                                 learning_rate=1,\n",
              "                                                 n_estimators=5,\n",
              "                                                 random_state=None))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=[0.1573248407643312, 0.16114649681528662,\n",
              "                          0.15414012738853503, 0.1464968152866242,\n",
              "                          0.19044585987261145, 0.19044585987261145])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cgD7EnB8Dnd"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B4zQvOq8M7H"
      },
      "source": [
        "y_pred = evc.predict(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}